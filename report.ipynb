{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача\n",
    "Необходимо написать классификатор картинок открытых (class=1)/закрытых (class=0)\n",
    "глаз, используя известную обучающую выборку. Решение будет проверяться на\n",
    "отложенной тестовой выборке (из того же распределения).\n",
    "\n",
    "Особенности задачи — выборка не содержит меток классов открытых или\n",
    "закрытых глаз. Полная либо частичная разметка выборки, unsupervised\n",
    "кластеризация и т.д. - все это является частью задачи.\n",
    "\n",
    "Решение должно быть реализовано на Python. Можно использовать любые\n",
    "библиотеки, но желательно не добавлять тяжеловесные зависимости без\n",
    "необходимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Текущий подход\n",
    "\n",
    "Supervised classification\n",
    "\n",
    "В тренировочном датасете 3600 изображений с глазами.\n",
    "\n",
    "Простая сверточная нейросеть, 66 тыс параметров.\n",
    "```\n",
    "Grayscale image 24 x 24 > Conv2d(1, 24, 3) > LeakyReLU > Pool(2) >\n",
    "                        > Conv2d(24, 48, 3) > LeakyReLU > Pool(2) > \n",
    "                        > Conv2d(48, 128, 3) > Dropout(0.1) > Fc(2)\n",
    "```\n",
    "\n",
    "При обучении использованы данные MRL eye dataset: http://mrl.cs.vsb.cz/eyedataset. Использована случайная подвыборка из 20000 изображений. Аугментации - RandomFlip, CLAHE, ShiftScaleRotate. Изначальный размер MRL выборки (около 80 000 изображений) был уменьшен, чтобы выровнять распределения (в MRL глаза всего 37 человек), в тренировочном - намного больше.\n",
    "\n",
    "Была вручную полностью размечена тренировочная выборка (заняло менее часа, сильно ускорено с помощью бейзлайнового простого решения). Разметка приложена в файле `assets.csv`. Бейзлайновое решение описано ниже.\n",
    "\n",
    "Размечать данные **необязательно** для решения этой задачи. В некоторых случаях разметка может быть очень дорогой, или в принципе недоступной. Конкретно в этой задаче она очень удобна, т.к. позволяет насчитывать метрики, и проверять простейшие решения.\n",
    "\n",
    "Золотое правило -- всегда сначала надо проверять самые тупые идеи - дают бейзлайн, позволяют анализировать данные и возникающие сложности.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Плюсы: \n",
    "\n",
    "Очень быстро работает, можно запускать инференс на CPU и на мобилках. Локальная скорость около 800 картинок /сек. Простая модель, мало параметров, легко тренится в условиях небольшого количества данных.\n",
    "\n",
    "Минусы:\n",
    "\n",
    "Нуждается в усилении (см. дальнейшие шаги)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество на валидации `acc=0.91, f1=0.91`. Это не очень много, можно сделать горадо лучше, но требуется больше времени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск решения\n",
    "\n",
    "`python3 inference.py /путь/до/папки`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решения за две строчки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это бейзлайновые решения, они работают хуже, но их можно было получить практически бесплатно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opencv + haar cascade\n",
    "\n",
    "В opencv есть предобученные детекторы landmarks на признаках Хаара. Как бейзлайн можно взять его. Идея в том, что он не срабатывает на закрытые глаза  (нет зрачков)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_haarcascade(img, scale=1.06):\n",
    "    eyes = eye_cascade.detectMultiScale(img, scale, 0, minSize=(4,4))\n",
    "    return len(eyes) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой классификатор работает очень быстро (более 4000 картинок/сек), и почти не требует мозга.\n",
    "\n",
    "Метрики на полном train:\n",
    "\n",
    "```\n",
    "acc: 0.83694\n",
    "pre: 0.81257\n",
    "rec: 0.84046\n",
    "f1 : 0.82628\n",
    "```\n",
    "\n",
    "Что значительно проигрывает сетям (часто ломается в каких-то сложных случаях)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### supervised classification pretrained model-zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть примитивный нейросетевой классификатор, обученный как раз на MRL eye dataset:\n",
    "https://docs.openvinotoolkit.org/latest/omz_models_model_open_closed_eye_0001.html\n",
    "\n",
    "Если вытащить ONNX граф и сконвертировать его в torch, то получится также простой классификатор, с нулем мозга.\n",
    "\n",
    "Точность сравнимая с opencv, f1 и acc порядка `0.81`.\n",
    "\n",
    "В этой модели гораздо меньше параметров, и она очень быстро работает. Есть квантизация.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что еще было проверено"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* различные архитектуры простейших сетей\n",
    "* взятые первые слои предобученных сетей с дотренировкой (resnext, vgg), показали себя сравнимо с EyeNet, но при этом гораздо более вычислительно трудоемки\n",
    "* попытки написать классификатор на HOG признаках, качество ниже, однако на tSNE видно, что классы можно хорошо разделить (см. `index.png`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# дальнейшие шаги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В первую очередь, найти больше данных. Есть еще датасеты с глазами.\n",
    "\n",
    "  Больше данных - можно увеличивать модель\n",
    "\n",
    "  Более того, можно найти много отдельных классов - например, много открытых глаз можно найти в каком-нибудь Celeb Dataset и разных facial expression датасетах.\n",
    "  \n",
    "* Поработать со сложными случаями (очки, блики, темная кожа, низкий контраст)\n",
    "\n",
    "* Больше подбора архитектуры\n",
    "\n",
    "* Сейчас думаю слабые места еще с нормализацией (ее нет), не и\n",
    "\n",
    "### для резерча еще можно попробовать\n",
    "\n",
    "* из классических методов EAR + landmarks по типу https://iopscience.iop.org/article/10.1088/1742-6596/1529/5/052015/pdf\n",
    "\n",
    "Проблемы - низкое разрешение\n",
    "\n",
    "* На случай, если разметка недоступна, или слишком дорога, можно посмотреть в сторону distance learning, простейший способ уменьшить количество разметки - вытащить вектор картинки любым предобученным backbone, разметить несколько сотен глаз, затем вссе закинуть в kNN, посмотреть, что получится\n",
    "\n",
    "* Также в сторону few shot classification, 1-shot\n",
    "\n",
    "* Можно попробовать обойтись вообще без разметки, подбор feature extract -> кластеризация\n",
    "\n",
    "* single class svm (хотя по опыту он почти никогда не работает)\n",
    "\n",
    "* автоэнкодеры, VAE\n",
    "\n",
    "* эмбеддинги по типу Arcface, self-supervised векторизация с последующим разделением\n",
    "\n",
    "* ... еще очень много идей, к сожалению, у меня уже закончилось время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
